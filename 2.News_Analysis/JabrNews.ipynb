{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<div align=center>\n",
        "\t\t\n",
        "<p></p>\n",
        "<p></p>\n",
        "<font size=5>\n",
        "In the Name of God\n",
        "<font/>\n",
        "<p></p>\n",
        " <br/>\n",
        "    <br/>\n",
        "    <br/>\n",
        "<font color=#FF7500>\n",
        "Sharif University of Technology - Departmenet of Computer Engineering\n",
        "</font>\n",
        "<p></p>\n",
        "<font color=blue>\n",
        "Linear Algebra \n",
        "<br>\n",
        "Prof. Hamid R. Rabiee\n",
        "<br>\n",
        "Dr. Maryam Ramezani\n",
        "</font>\n",
        "<br/>\n",
        "<br/>\n",
        "Fall 2022\n",
        "\n",
        "</div>\n",
        "\n",
        "<hr/>\n",
        "\t\t<div align=center>\n",
        "\t\t    <font color=red size=6>\n",
        "\t\t\t    <br />\n",
        "Project - Q2 <br>\n",
        "Jabr News\n",
        "\n",
        "(65% of the overall project grade)\n",
        "            \t<br/>\n",
        "\t\t\t</font>\n",
        "<font size=4>\n",
        "\t\t\t<br/><br/>\n",
        "<font color=red>\n",
        "Please run all the cells.\n",
        "     </font>\n",
        "</font>\n",
        "<br>\n",
        "<font size=3 color=grey>\n",
        "</font>\n",
        "    </div>"
      ],
      "metadata": {
        "id": "DhBJ3AaRMPHv"
      },
      "id": "DhBJ3AaRMPHv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name:\n",
        "<br>\n",
        "Student Number:"
      ],
      "metadata": {
        "id": "IcWtgUUnNEsE"
      },
      "id": "IcWtgUUnNEsE"
    },
    {
      "cell_type": "markdown",
      "id": "attempted-chance",
      "metadata": {
        "id": "attempted-chance"
      },
      "source": [
        "\n",
        "# JABR NEWS\n",
        "The JabrNews system, which has been established recently, has managed to find a lot of news from all over the world daily and put it in its system. Despite the site being new, it has attracted alot of fans.\n",
        "<br>\n",
        "<br>\n",
        "This system receives a lot of news every day, most of which are about certain topics, and should be classified by a system. Unfortunately, due to the low speed of the internet, today their system does not have the ability to do the task, so they need your help to do this for them.\n",
        "<br>\n",
        "<br>\n",
        "Take the following steps to fulfil the task.\n",
        "<br>\n",
        "<br>\n",
        "Import any libraries that you may need.\n",
        "\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "neither-europe",
      "metadata": {
        "id": "neither-europe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "acting-jaguar",
      "metadata": {
        "id": "acting-jaguar"
      },
      "source": [
        "# Data Matrix ( 30 points )\n",
        "<br>\n",
        "<br>\n",
        "First, we need to create the data matrix to be able to work with it. We consider each file as a row of this matrix.\n",
        "<br>\n",
        "<br>\n",
        "Before creating this matrix, it is necessary to prepare the corpus related to these files. Corpus is the set of all words that are in the text files. Also, note that you will be given a file called stopwords that you should not include in the corpus.\n",
        "<br>\n",
        "<br>\n",
        "The second thing you should consider is that words like Programming, Programmer are counted as one word. For this, you can use the nltk library.\n",
        "<br>\n",
        "<br>\n",
        "(If you have a problem in building the corpus or the number of words in the corpus exceeds some limit, you can first find the number of repetitions of each word in the corpus and use a limited number of them.)\n",
        "\n",
        "\n",
        "\n",
        "### Subtask 1 : Create corpus "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "extensive-williams",
      "metadata": {
        "id": "extensive-williams"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "electrical-observer",
      "metadata": {
        "id": "electrical-observer"
      },
      "source": [
        "Now, according to the corpus we created, we need to create an initial data matrix. In such a way that the index $ij$ in the matrix $Y$ has the value $k$ if the word $j$ is repeated $k$ times in the corpus in the text $i$.\n",
        "\n",
        "\n",
        "### Subtask 2 : Create initial data matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "creative-eating",
      "metadata": {
        "id": "creative-eating"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "fitting-backup",
      "metadata": {
        "id": "fitting-backup"
      },
      "source": [
        "In this part, we want to complete the data matrix. Consider the following definitions:\n",
        "    <br>\n",
        "    <br>\n",
        "$$\n",
        "t_{ij} = Y_{ij}\n",
        "$$\n",
        "    <br>\n",
        "    <br>\n",
        "$$\n",
        "\\text{idf}_{i} = \\text{Number of text files having word }i\\text{ in corpus}\n",
        "$$\n",
        "    <br>\n",
        "    <br>\n",
        "    $$\n",
        "    N = \\text{Number of text files}\n",
        "    $$\n",
        "    <br>\n",
        "    <br>\n",
        "Note that here $t$ is the number of word repetitions in a text. According to these definitions, the data matrix is ​​defined as follows:\n",
        "<br>\n",
        "    <br>\n",
        "    $$\n",
        "    X_{ij} = t_{ij}\\times\\text{Log}(\\frac{N}{\\text{idf}_j})\n",
        "    $$\n",
        "    <br>\n",
        "    <br>\n",
        "This method is called tf-idf. Finally, each row of the data matrix must have a norm of 1.\n",
        "\n",
        "### Subtask 3 : Create Data matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "instrumental-glenn",
      "metadata": {
        "id": "instrumental-glenn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "simple-point",
      "metadata": {
        "id": "simple-point"
      },
      "source": [
        "# SVD ( 30 points )\n",
        "<br>\n",
        "<br>\n",
        "Here we present the first solution. Using SVD, we try to write the matrix $X$ which is $N\\times\\text{Corpus}$ in the form $VU$ in which we have $V_{N\\times k}$ and $U_{k\\times C}$.\n",
        "<br>\n",
        "<br>\n",
        "(If the execution of SVD takes a long time, you can limit the number of words in the corpus as desired.)\n",
        "\n",
        "\n",
        "### Subtask 1 : Run SVD on Data Matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "introductory-hartford",
      "metadata": {
        "id": "introductory-hartford"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "complicated-opportunity",
      "metadata": {
        "id": "complicated-opportunity"
      },
      "source": [
        "Now, having the SVD answer, take an arbitrary number (for example, $k = 10$) to pick the largest values of $\\sigma$ and select its corresponding vectors in $U$ and $V$. (Multiply the value of $\\sigma$ in one of $U$ or $V$ so that we can write $X$ as a product of $VU$.)\n",
        "    <br>\n",
        "    <br>\n",
        "    $$\n",
        "    X = VU\n",
        "    $$\n",
        "    <br>\n",
        "    <br>\n",
        "Now if we have:\n",
        "<br>\n",
        "    <br>\n",
        "    $$\n",
        "    V = \\begin{bmatrix}v_1^T\\\\\\vdots\\\\v_N^T\\end{bmatrix}\\quad,\\quad v_i \\in \\mathbb{R}^k\\quad,\\quad U\\in\\mathbb{R}^{k\\times C}\n",
        "    $$\n",
        "    <br>\n",
        "    <br>\n",
        "As a result, each line of $X$ is written as follows.\n",
        "<br>\n",
        "    <br>\n",
        "    $$\n",
        "    X = \\begin{bmatrix}v_1^TU\\\\\\vdots\\\\v_N^TU\\end{bmatrix}\n",
        "    $$\n",
        "    <br>\n",
        "    <br>\n",
        "Now, this expression can be interpreted in such a way that each of the $k$ rows in $U$ specify a specific topic. And each of the $v_i^t$ elements specifies how much the text $i$ is related to that topic. Basically, we are trying to display each text as a linear combination of several different topics.\n",
        "<br>\n",
        "    <br>\n",
        "For $k=10$ different topics, specify which topic each text belongs to.\n",
        "### Subtask 2 : Use SVD for clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "standard-champion",
      "metadata": {
        "id": "standard-champion"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "fixed-northwest",
      "metadata": {
        "id": "fixed-northwest"
      },
      "source": [
        "In the $U$ matrix where the topics are in the rows, we know that every 2 rows are perpendicular to each other. Is this assumption correct for different subjects?\n",
        "    <br>\n",
        "    <br>\n",
        "    What does it mean if the coefficient of a subject is negative for a particular text? Do we have the power to interpret negative coefficients?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "unknown-tennis",
      "metadata": {
        "id": "unknown-tennis"
      },
      "source": [
        "In this part, we want to measure the accuracy of the model. At first, it is necessary to project the $X$ matrix that we made earlier using PCA, on 2 dimensions and assign to each of points a color corresponding to their labels that you obtained in Subtask 2.\n",
        "\n",
        "### Subtask 3 : Use PCA on X and labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "immediate-steering",
      "metadata": {
        "id": "immediate-steering"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "steady-german",
      "metadata": {
        "id": "steady-german"
      },
      "source": [
        "# New Factorizaion ( 30 points )\n",
        "<br>\n",
        "<br>\n",
        "As you must have noticed in the previous section, there is room for improvement compared to the SVD method. Here we introduce a new method that has advantages over SVD.\n",
        "<br>\n",
        "<br>\n",
        "Here we try to write the matrix $X$ in the form $X \\sim WH$. But contrary to the SVD method, we try to ensure that all the domains of $H$ and $W$ are positive, and with this condition, we seek to find $H$ and $W$ that minimize the following function:\n",
        "<br>\n",
        "    <br>\n",
        "    $$\n",
        "    J = \\lVert X - WH\\lVert^2_F\n",
        "    $$\n",
        "<br>\n",
        "    <br>\n",
        "Use the following algorithm to find such two matrices.\n",
        "<br>\n",
        "    <br>\n",
        "    First, create the matrix $W$ and $H$ with random positive elements. Next, repeat the following step max_iter times and save $H, W$ for which we have the least error.\n",
        "    <br>\n",
        "    <br>\n",
        "    $$\n",
        "    H_{ij} := H_{ij}\\frac{(W^TX)_{ij}}{(W^TWH + 10^{-9})_{ij}}\n",
        "    $$\n",
        "    $$\n",
        "    W_{ij} := W_{ij}\\frac{(XH^T)_{ij}}{(WHH^T + 10^{-9})_{ij}}\n",
        "    $$\n",
        "    <br>\n",
        "    <br>\n",
        "Considering that the answer of $W$ and $H$ is not unique, it is necessary to set the norm of each row of $H$ equal to 1 in each step after the update and also apply a change in $W$ that the answer of their multiplication Does not change.\n",
        "\n",
        "### Subtask 1 : Find W, H."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "professional-tower",
      "metadata": {
        "id": "professional-tower"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "isolated-radical",
      "metadata": {
        "id": "isolated-radical"
      },
      "source": [
        "Now, as in the previous section, we want to know what topic each text belongs to. Each topic is a row of $H$ and we have no requirement for them to be perpendicular to each other. For $k=10$ determine what topic each text belongs to.\n",
        "    <br>\n",
        "    <br>\n",
        "    As in the previous section, measure the accuracy of this method intuitively.\n",
        "### Subtask 2 : Use W, H for clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "excited-perfume",
      "metadata": {
        "id": "excited-perfume"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "cosmetic-baltimore",
      "metadata": {
        "id": "cosmetic-baltimore"
      },
      "source": [
        "\n",
        "Has the constrain on $W, H$ helped us with the clustering? Explain."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "decent-subject",
      "metadata": {
        "id": "decent-subject"
      },
      "source": [
        "In this section, in addition to specifying the topic of each text, you must also specify the topic itself. This means that some of the largest values in row $i$ in matrix $H$, which is a word in the corpus, determine what the general scope of a subject is.\n",
        "\n",
        "### Subtask 3 : Show some of the topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "romance-attempt",
      "metadata": {
        "id": "romance-attempt"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}